# Dataset Generator

Web scraping and automatic dataset generation tool for question-answer datasets with advanced export capabilities and LLM integration.

## ðŸŽ¯ Objective

Create quality datasets for training AI models by automatically scraping reliable sources and generating contextualized question-answer pairs. Export datasets to multiple formats including Langfuse for training data management.

## âš¡ Quick Start

```bash
# Configuration
cp .env.example .env
# Edit .env with your API keys

# Launch
make start
```

## ðŸ—ï¸ Architecture

This project is designed with a modular architecture that separates concerns into distinct components:

- **Scraper**: Retrieval of web content from specified URLs
- **LLM Client**: Interaction with language models to generate question-answer pairs
- **Data Manager**: Data management and dataset storage with multiple export formats
- **Pipeline**: Orchestration of the complete dataset generation process
- **Export Module**: Advanced dataset export to various platforms (Langfuse, JSON, CSV, etc.)

## âœ¨ Key Features

- **Multi-source Scraping**: Support for various web sources and content types
- **AI-Powered QA Generation**: Leverage state-of-the-art LLMs for intelligent question-answer pair creation
- **Langfuse Integration**: Direct export to Langfuse for dataset management and training workflows
- **Multiple Export Formats**: JSON, CSV, JSONL, and platform-specific formats
- **Quality Control**: Automated validation and filtering of generated content
- **Batch Processing**: Efficient handling of large-scale data generation
- **API Interface**: RESTful API for programmatic access and integration

## ðŸ“š Libraries Used

- **requests** >= 2.32.5 â€” HTTP requests for scraping
- **scrapy** >= 2.13.3 â€” Structured data extraction from HTML
- **fake-useragent** >= 2.2.0 â€” User-agent rotation to avoid scraping detection
- **openai** >= 1.102.0 â€” OpenAI API client for text processing
- **instructor** >= 1.10.0 â€” Tools to build structured LLM prompts / structured outputs
- **python-dotenv** >= 0.9.9 â€” Load environment variables from a .env file
- **fastapi** >= 0.116.1 â€” API framework used by the service
- **pytest** >= 8.4.1 â€” Testing framework
- **langfuse** â€” Integration with Langfuse platform for dataset management

## ðŸ”„ Workflow

1. **Scraping**: Retrieving raw web data from multiple sources
2. **Cleaning**: Processing and normalizing text to extract relevant content
3. **QA Generation**: Creating high-quality question-answer pairs via LLMs with configurable prompts
4. **Quality Assurance**: Automated validation and filtering of generated datasets
5. **Export**: Multi-format export including Langfuse integration for seamless training workflows
6. **Storage**: Persistent storage with metadata tracking and version control

## ðŸ“Š Export Options

- **Langfuse**: Direct integration for training data management
- **JSON/JSONL**: Standard formats for data interchange
- **CSV**: Tabular format for analysis and review
- **Custom Formats**: Extensible export system for specific requirements

## ðŸ”§ Configuration

The tool supports extensive configuration options for:

- LLM model selection and parameters
- Export format preferences
- Quality thresholds and validation rules
- Batch processing settings
- API rate limiting and retry policies
